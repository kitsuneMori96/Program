import requests
import time
import os
import random
import urllib3

# ç¦ç”¨SSLè¯ä¹¦éªŒè¯è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def get_max_number(save_dir):
    """æ™ºèƒ½è·å–ç›®å½•ä¸­æœ€å¤§å›¾ç‰‡ç¼–å·ï¼ˆæ”¯æŒä¸è¿ç»­ç¼–å·ï¼‰"""
    max_num = 0
    if os.path.exists(save_dir):
        for filename in os.listdir(save_dir):
            if filename.endswith('.jpg'):
                try:
                    num = int(os.path.splitext(filename)[0])
                    max_num = max(max_num, num)
                except ValueError:
                    continue
    return max_num

def download_images(save_dir='images', max_retries=5):
    # è¯·æ±‚å¤´è®¾ç½®ï¼ˆæ¨¡æ‹Ÿæœ€æ–°ç‰ˆEdgeæµè§ˆå™¨ï¼‰
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0',
        'Referer': 'https://www.google.com/'
    }

    # æ„å»ºURLæ¨¡æ¿
    base_url = "https://tsundora.com/image/2015/09/irotoridori_no_sekai_"
    url_template = f"{base_url}/{{}}.jpg"

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    
    # åˆå§‹åŒ–ä¸‹è½½å‚æ•°
    num = get_max_number(save_dir) + 1
    retry_count = 0
    success_count = 0

    while retry_count < max_retries:
        file_path = os.path.join(save_dir, f'{num}.jpg')
        
        # è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶
        if os.path.exists(file_path):
            print(f'â© è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶ï¼š{num}.jpg')
            num += 1
            success_count += 1
            continue

        try:
            # å‘é€è¯·æ±‚ï¼ˆåŒ…å«åŠ¨æ€è¶…æ—¶ï¼‰
            response = requests.get(
                url_template.format(num),
                headers=headers,
                verify=False,
                timeout=random.uniform(5, 10)  # åŠ¨æ€è¶…æ—¶è®¾ç½®
            )

            # å¤„ç†å“åº”
            if response.status_code == 200:
                # ä¿å­˜å›¾ç‰‡
                with open(file_path, 'wb') as f:
                    f.write(response.content)
                print(f'âœ… æˆåŠŸä¸‹è½½ [{num}.jpg] | å¤§å°ï¼š{len(response.content)//1024}KB')
                num += 1
                success_count += 1
                retry_count = 0
            elif response.status_code == 404:
                print(f'â›” ç»ˆæ­¢ä¸‹è½½ï¼š{num}.jpg ä¸å­˜åœ¨')
                break
            else:
                print(f'âš  å¼‚å¸¸çŠ¶æ€ç  [{response.status_code}]ï¼Œæ­£åœ¨é‡è¯•...')
                retry_count += 1

        except requests.exceptions.RequestException as e:
            print(f'âš  ç½‘ç»œå¼‚å¸¸ï¼š{type(e).__name__}ï¼Œæ­£åœ¨é‡è¯•...')
            retry_count += 1

        # åŠ¨æ€ç­‰å¾…æ—¶é—´ï¼ˆ0.5-2.5ç§’éšæœºé—´éš”ï¼‰
        sleep_time = random.uniform(0.5, 1.5)
        time.sleep(sleep_time)

    print('\n============== ä¸‹è½½æŠ¥å‘Š ==============')
    print(f'âœ… æˆåŠŸä¸‹è½½æ•°é‡ï¼š{success_count}')
    print(f'â© è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶ï¼š{num - get_max_number(save_dir) - 1}')
    print(f'ğŸ“ å­˜å‚¨è·¯å¾„ï¼š{os.path.abspath(save_dir)}')

if __name__ == '__main__':
    download_images(save_dir='downloaded_images')
